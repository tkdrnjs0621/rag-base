{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "import torch\n",
    "import argparse\n",
    "import re\n",
    "import time\n",
    "from datetime import timedelta\n",
    "from functools import partial\n",
    "import logging\n",
    "from datasets import load_dataset, Dataset\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from src.retriever import Retriever\n",
    "from types import SimpleNamespace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['CUDA_VISIBLE_DEVICES']='1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: facebook/contriever-msmarco\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tkdrnjs0621/miniconda3/envs/torch_241/lib/python3.9/site-packages/transformers/tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Indexing passages from files ['data/corpus/wikipedia_embeddings/passages_00', 'data/corpus/wikipedia_embeddings/passages_01', 'data/corpus/wikipedia_embeddings/passages_02', 'data/corpus/wikipedia_embeddings/passages_03', 'data/corpus/wikipedia_embeddings/passages_04', 'data/corpus/wikipedia_embeddings/passages_05', 'data/corpus/wikipedia_embeddings/passages_06', 'data/corpus/wikipedia_embeddings/passages_07', 'data/corpus/wikipedia_embeddings/passages_08', 'data/corpus/wikipedia_embeddings/passages_09', 'data/corpus/wikipedia_embeddings/passages_10', 'data/corpus/wikipedia_embeddings/passages_11', 'data/corpus/wikipedia_embeddings/passages_12', 'data/corpus/wikipedia_embeddings/passages_13', 'data/corpus/wikipedia_embeddings/passages_14', 'data/corpus/wikipedia_embeddings/passages_15']\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_00\n",
      "Total data indexed 1000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_01\n",
      "Total data indexed 2000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_02\n",
      "Total data indexed 3000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_03\n",
      "Total data indexed 4000000\n",
      "Total data indexed 5000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_04\n",
      "Total data indexed 6000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_05\n",
      "Total data indexed 7000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_06\n",
      "Total data indexed 8000000\n",
      "Total data indexed 9000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_07\n",
      "Total data indexed 10000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_08\n",
      "Total data indexed 11000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_09\n",
      "Total data indexed 12000000\n",
      "Total data indexed 13000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_10\n",
      "Total data indexed 14000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_11\n",
      "Total data indexed 15000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_12\n",
      "Total data indexed 16000000\n",
      "Total data indexed 17000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_13\n",
      "Total data indexed 18000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_14\n",
      "Total data indexed 19000000\n",
      "Loading file data/corpus/wikipedia_embeddings/passages_15\n",
      "Total data indexed 20000000\n",
      "Total data indexed 21000000\n",
      "Total data indexed 21015324\n",
      "Data indexing completed.\n",
      "Indexing time: 240.4 s.\n",
      "loading passages\n",
      "passages have been loaded\n"
     ]
    }
   ],
   "source": [
    "\n",
    "arg = SimpleNamespace()\n",
    "arg.retrieval_model_name_or_path=\"facebook/contriever-msmarco\"\n",
    "arg.retrieval_embedding_size=768\n",
    "arg.passages='data/corpus/psgs_w100.tsv'\n",
    "arg.passages_embeddings='data/corpus/wikipedia_embeddings/*'\n",
    "arg.indexing_batch_size=1000000\n",
    "arg.save_or_load_index = False\n",
    "arg.retrieval_n_subquantizers=0\n",
    "arg.retrieval_n_bits=8\n",
    "arg.max_k=100\n",
    "arg.lowercase = False\n",
    "arg.normalize_text = False\n",
    "arg.per_gpu_batch_size=1000000\n",
    "arg.question_maxlength=100000\n",
    "\n",
    "retriever = Retriever(arg)\n",
    "retriever.setup_retriever()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever.reset_args(arg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "dataset = Dataset.from_json(\"data/eval_data/triviaqa_test.jsonl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who was the man behind The Chipmunks?\n",
      "['David Seville', 'david seville']\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'cpu'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mquestion\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(dataset[idx][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124manswers\u001b[39m\u001b[38;5;124m'\u001b[39m])\n\u001b[0;32m----> 4\u001b[0m rs \u001b[38;5;241m=\u001b[39m \u001b[43mretriever\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msearch_document\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mquestion\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_n\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m a \u001b[38;5;129;01min\u001b[39;00m rs:\n\u001b[1;32m      6\u001b[0m     \u001b[38;5;28mprint\u001b[39m(a)\n",
      "File \u001b[0;32m~/work/ragframework/src/retriever.py:126\u001b[0m, in \u001b[0;36mRetriever.search_document\u001b[0;34m(self, query, top_n)\u001b[0m\n\u001b[1;32m    125\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msearch_document\u001b[39m(\u001b[38;5;28mself\u001b[39m, query, top_n\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m10\u001b[39m):\n\u001b[0;32m--> 126\u001b[0m     questions_embedding \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_queries\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    128\u001b[0m     \u001b[38;5;66;03m# get top k results\u001b[39;00m\n\u001b[1;32m    129\u001b[0m     start_time_retrieval \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m~/work/ragframework/src/retriever.py:52\u001b[0m, in \u001b[0;36mRetriever.embed_queries\u001b[0;34m(self, args, queries)\u001b[0m\n\u001b[1;32m     50\u001b[0m             encoded_batch \u001b[38;5;241m=\u001b[39m {k: v\u001b[38;5;241m.\u001b[39mcuda() \u001b[38;5;28;01mfor\u001b[39;00m k, v \u001b[38;5;129;01min\u001b[39;00m encoded_batch\u001b[38;5;241m.\u001b[39mitems()}\n\u001b[1;32m     51\u001b[0m             output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmodel(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mencoded_batch)\n\u001b[0;32m---> 52\u001b[0m             embeddings\u001b[38;5;241m.\u001b[39mappend(\u001b[43moutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcpu\u001b[49m())\n\u001b[1;32m     54\u001b[0m             batch_question \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     56\u001b[0m embeddings \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mcat(embeddings, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'BaseModelOutputWithPoolingAndCrossAttentions' object has no attribute 'cpu'"
     ]
    }
   ],
   "source": [
    "idx = 0\n",
    "print(dataset[idx]['question'])\n",
    "print(dataset[idx]['answers'])\n",
    "rs = retriever.search_document(dataset[idx]['question'], top_n=10)\n",
    "for a in rs:\n",
    "    print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "torch_241",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
